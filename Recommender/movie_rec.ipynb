{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\major\\AppData\\Local\\Temp\\ipykernel_20432\\810014516.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import re\n",
    "\n",
    "# User ratings from letterboxd csv \n",
    "ratings = pd.read_csv(\"ratings.csv\", usecols=['Name', 'Rating', 'Year'])\n",
    "#ratings = ratings.drop(columns=['Date', 'Letterboxd URI'])\n",
    "\n",
    "# Collection of movie titles with their genres\n",
    "movies = pd.read_csv(\"movies.csv\")\n",
    "# Remove (year) from titles\n",
    "movies[['title', 'year']] = movies['title'].str.extract(r'^(.*)\\s\\((\\d{4})\\)$')\n",
    "movies['year'] = pd.to_numeric(movies['year'], errors='coerce')\n",
    "movies['year'] = movies['year'].fillna(0).astype(int)\n",
    "# Remove Nan titles\n",
    "movies = movies.dropna(subset=['title']).reset_index(drop=True)\n",
    "movies = movies.drop_duplicates(subset=['title', 'year']).reset_index(drop=True)\n",
    "\n",
    "movies['title_clean'] = movies['title'].str.replace(r'\\s*\\(.*\\)\\s*$', '', regex=True)\n",
    "mask = movies['title_clean'].str.endswith(', The')\n",
    "movies.loc[mask, 'title_clean'] = 'The ' + movies.loc[mask, 'title_clean'].str[:-5]\n",
    "movies['title'] = movies['title_clean']\n",
    "movies = movies.drop(columns=['title_clean'])\n",
    "\n",
    "# Colletion of ratings to be used in the correlation matrix.\n",
    "all_ratings = pd.read_csv(\"allratings.csv\")\n",
    "all_ratings = all_ratings.drop(columns=['timestamp'])\n",
    "all_ratings = all_ratings.dropna(subset=['userId', 'movieId', 'rating'])\n",
    "# Merge movies into all_ratings to have title, genres, and year\n",
    "all_ratings = pd.merge(all_ratings, movies)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['(no genres listed)', 'Action', 'Adventure', 'Animation', 'Children', 'Comedy', 'Crime', 'Documentary', 'Drama', 'Fantasy', 'Film-Noir', 'Horror', 'IMAX', 'Musical', 'Mystery', 'Romance', 'Sci-Fi', 'Thriller', 'War', 'Western']\n"
     ]
    }
   ],
   "source": [
    "# List of genres\n",
    "genres = set()\n",
    "\n",
    "for genre in all_ratings['genres']:\n",
    "    gs = genre.split('|')\n",
    "    for g in gs:\n",
    "        genres.add(g)\n",
    "\n",
    "print(sorted(genres))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low: 1874, High: 2023\n"
     ]
    }
   ],
   "source": [
    "# Year Range of dataset\n",
    "low = 2026\n",
    "high = 0\n",
    "\n",
    "for year in all_ratings['year']:\n",
    "    low = min(low, year)\n",
    "    high = max(high, year)\n",
    "\n",
    "print(f\"Low: {low}, High: {high}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movies: 12145\n"
     ]
    }
   ],
   "source": [
    "# Limit the included movies to movies with a minimum number of ratings\n",
    "ratings_per_movie = all_ratings.groupby('movieId').size()\n",
    "accepted_movies = ratings_per_movie[ratings_per_movie >= 100].index\n",
    "filtered_ratings = all_ratings[all_ratings['movieId'].isin(accepted_movies)]\n",
    "num_movies = filtered_ratings['movieId'].nunique()\n",
    "print(f\"Movies: {num_movies}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\major\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\neighbors\\_base.py:584: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n"
     ]
    }
   ],
   "source": [
    "from scipy.sparse import coo_matrix\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "user_ids = filtered_ratings['userId'].astype('category').cat.codes\n",
    "movie_ids = filtered_ratings['movieId'].astype('category').cat.codes\n",
    "rating_values = filtered_ratings['rating']\n",
    "\n",
    "sparse_matrix = coo_matrix((rating_values, (user_ids, movie_ids))).tocsr()\n",
    "movie_index_to_id = dict(enumerate(filtered_ratings['movieId'].astype('category').cat.categories))\n",
    "movie_id_to_index = {v: k for k, v in movie_index_to_id.items()}\n",
    "\n",
    "def kMostSimilar(sparse_matrix, k):\n",
    "    norm_mat = normalize(sparse_matrix.T, norm='l2', axis=1)\n",
    "    model = NearestNeighbors(n_neighbors=k, metric='euclidean', algorithm='ball_tree', n_jobs=-1)\n",
    "    model.fit(norm_mat)\n",
    "    dists, inds = model.kneighbors(norm_mat)\n",
    "    sims = 1 - (dists**2 / 2)\n",
    "    return inds, sims\n",
    "\n",
    "topk_inds, topk_sims = kMostSimilar(sparse_matrix, k=50)\n",
    "global_mean = filtered_ratings['rating'].mean()\n",
    "movie_means = filtered_ratings.groupby('movieId')['rating'].mean().to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15960, 15960)\n"
     ]
    }
   ],
   "source": [
    "from scipy.sparse import coo_matrix\n",
    "movie_to_info = None\n",
    "\n",
    "def calculate_similarity(sparse_matrix):\n",
    "    # Calculate the cosine similarity between movies. Transpose the matrix to find item-item similarity instead of user-user\n",
    "    similarity = cosine_similarity(sparse_matrix.T, dense_output=False)\n",
    "    \n",
    "    # Calculate the signifance of the correlation based on the number of ratings. i.e more ratings should mean more impact on the correlation calculation\n",
    "    n_ratings = (sparse_matrix != 0).sum(axis=0)\n",
    "    min_ratings = 50\n",
    "    significance_matrix = n_ratings.T.dot(n_ratings) / (n_ratings.T.dot(n_ratings) + min_ratings)\n",
    "    \n",
    "    return similarity.multiply(significance_matrix)\n",
    "\n",
    "# Make a matrix of all movie correlations\n",
    "def make_matrix(filtered_ratings):    \n",
    "    global movie_to_info\n",
    "    user_ids = filtered_ratings['userId'].astype('category').cat.codes\n",
    "    movie_ids = filtered_ratings['movieId'].astype('category').cat.codes\n",
    "    rating_values = filtered_ratings['rating']\n",
    "    \n",
    "    # Sparse matrix made with coo_matrix to include only non 0 values, therefore saving space and time\n",
    "    sparse_matrix = coo_matrix((rating_values, (user_ids, movie_ids))).tocsr()\n",
    "    \n",
    "    movie_similarity = calculate_similarity(sparse_matrix)\n",
    "    \n",
    "    movies = filtered_ratings['movieId'].astype('category').cat.categories\n",
    "    movie_similarity_df = pd.DataFrame(\n",
    "        movie_similarity.toarray(),\n",
    "        index=movies,\n",
    "        columns=movies\n",
    "    )\n",
    "\n",
    "    movie_to_info = filtered_ratings[['movieId', 'title', 'genres', 'year']].drop_duplicates().set_index('movieId')\n",
    "    \n",
    "    return movie_similarity_df\n",
    "\n",
    "sparse_matrix = make_matrix(filtered_ratings)\n",
    "global_mean = filtered_ratings['rating'].mean()\n",
    "movie_means = filtered_ratings.groupby('movieId')['rating'].mean().to_dict()\n",
    "print(sparse_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_user_ratings_to_movieids(user_df, filtered_ratings):\n",
    "    # Create a lookup of title+year to movieId for exact matches\n",
    "    title_year_to_id = filtered_ratings.groupby(['title', 'year'])['movieId'].first().to_dict()\n",
    "    \n",
    "    mapped_ratings = []\n",
    "    not_found = []\n",
    "    \n",
    "    for _, row in user_df.iterrows():\n",
    "        user_title = row['Name']\n",
    "        user_year = row.get('Year', None)\n",
    "        \n",
    "        # Try exact match first with title+year\n",
    "        if user_year and (user_title, user_year) in title_year_to_id:\n",
    "            movie_id = title_year_to_id[(user_title, user_year)]\n",
    "            mapped_ratings.append({\n",
    "                'movieId': movie_id,\n",
    "                'Rating': row['Rating'],\n",
    "                'original_title': user_title\n",
    "            })\n",
    "            continue\n",
    "        \n",
    "        else:\n",
    "            not_found.append((user_title, user_year))\n",
    "\n",
    "    mapped_df = pd.DataFrame(mapped_ratings)\n",
    "    \n",
    "    return mapped_df, not_found\n",
    "\n",
    "# Map user ratings to movieIds\n",
    "ratings_with_ids, not_found = map_user_ratings_to_movieids(ratings, filtered_ratings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Glass Onion', 2022), ('Avengers: Infinity War', 2018), ('Black Panther', 2018), ('Spider-Man: Homecoming', 2017), (\"Harry Potter and the Philosopher's Stone\", 2001), ('Guardians of the Galaxy Vol. 2', 2017), ('A Silent Voice: The Movie', 2016), ('Captain Marvel', 2019), ('Pokémon Detective Pikachu', 2019), ('Entergalactic', 2022), ('Star Wars: Episode I – The Phantom Menace', 1999), ('Devilman Crybaby', 2018), ('Demon Slayer -Kimetsu no Yaiba- The Movie: Mugen Train', 2020), ('Cyberpunk: Edgerunners', 2022), ('The Last: Naruto the Movie', 2014), ('Your Lie in April', 2014), ('Hotarubi no Mori e', 2011), ('AnoHana: The Flower We Saw That Day', 2011), ('Words Bubble Up Like Soda Pop', 2020), ('Violet Evergarden: Eternity and the Auto Memory Doll', 2019), ('Bubble', 2022), ('Violet Evergarden: The Movie', 2020), ('Demon Slayer: Kimetsu no Yaiba', 2019), ('Fireworks', 2017), ('Tokyo Ghoul', 2014), ('Bakemonogatari', 2009), ('Kotaro Lives Alone', 2022), ('Flowers of Evil', 2013), ('Great Pretender', 2020), ('Death Parade', 2015), ('Blue Period', 2021), ('Wotakoi: Love Is Hard for Otaku', 2018), ('Grand Blue Dreaming', 2018), ('Orange', 2016), ('Blue Spring Ride', 2014), ('Horimiya', 2021), ('Vinland Saga', 2019), ('Star Wars', 1977), ('Black Mirror: Striking Vipers', 2019), ('Black Mirror: The Entire History of You', 2011), ('Avengers: Endgame', 2019), ('Black Mirror: Fifteen Million Merits', 2011), ('Sherlock: A Study in Pink', 2010), ('Sherlock: The Blind Banker', 2010), ('Sherlock: The Great Game', 2010), ('Sherlock: A Scandal in Belgravia', 2012), ('What Happens in Vegas', 2008), ('Meet Cute', 2022), (\"Komi Can't Communicate\", 2021), ('A Clockwork Orange', 1971), ('Toradora!', 2008), ('DARLING in the FRANXX', 2018), ('Monster', 2004), ('John Wick: Chapter 2', 2017), ('Night Teeth', 2021), ('The Kissing Booth 3', 2021), (\"Kuroko's Basketball the Movie: Last Game\", 2017), (\"He's All That\", 2021), ('The Perfect Date', 2019), ('Fatherhood', 2021), ('All the Bright Places', 2020), ('Look Both Ways', 2022), ('Guardians of the Galaxy Vol. 3', 2023), ('Maze Runner: The Scorch Trials', 2015), ('Return of the Jedi', 1983), ('The Blind Side', 2009), ('The Lorax', 2012), ('Monsters vs Aliens', 2009), ('Big Time Adolescence', 2019), ('Black Mirror: The National Anthem', 2011), ('Black Mirror: Be Right Back', 2013), ('You Are So Not Invited to My Bat Mitzvah', 2023), ('Black Mirror: White Bear', 2013), ('The School for Good and Evil', 2022), ('Spider-Man: Far From Home', 2019), ('Star Wars: Episode III –\\xa0Revenge of the Sith', 2005), ('A Nightmare on Elm Street', 1984), ('An American Werewolf in London', 1981), ('Black Mirror: The Waldo Moment', 2013), ('Black Mirror: White Christmas', 2014), ('The Texas Chain Saw Massacre', 1974), ('Black Mirror: Nosedive', 2016), ('Black Mirror: Playtest', 2016), ('Black Mirror: Shut Up and Dance', 2016), ('Gone in Sixty Seconds', 2000), ('The Killer', 2023), ('Star Wars: The Force Awakens', 2015), ('Sherlock: The Hounds of Baskerville', 2012), ('Sherlock: The Reichenbach Fall', 2012), ('Teenage Mutant Ninja Turtles: We Wish You a Turtle Christmas', 1994), ('Thingu', 2012), ('The Godfather Part II', 1974), ('Marcel the Shell with Shoes On', 2021), ('Kingsman: The Secret Service', 2014), ('Oldboy', 2003), ('Hawkeye', 2021), ('GoodFellas', 1990), ('Cross Road', 2014), ('Free Guy', 2021), ('Rascal Does Not Dream of Bunny Girl Senpai', 2018), (\"SHIMONETA: A Boring World Where the Concept of Dirty Jokes Doesn't Exist\", 2015), ('ERASED', 2016), ('Domestic Girlfriend', 2019), ('No Game No Life', 2014), ('Tower of God', 2020), ('The Pet Girl of Sakurasou', 2012), ('The Future Diary', 2011), ('Plastic Memories', 2015), (\"Masamune-kun's Revenge\", 2017), ('How Heavy Are the Dumbbells You Lift?', 2019), ('Akame ga Kill!', 2014), ('Handa-kun', 2016), ('Classroom of the Elite', 2017), ('Charlotte', 2015), ('GAMERS!', 2017), ('Oreshura', 2013), ('Cautious Hero: The Hero Is Overpowered but Overly Cautious', 2019), ('Yamada-kun and the Seven Witches', 2015), ('Golden Time', 2013), ('AHO-GIRL', 2017), ('Chivalry of a Failed Knight', 2015), ('Just Because!', 2017), ('ORESUKI Are you the only one who loves me?', 2019), ('Campione!', 2012), ('TONIKAWA: Over the Moon for You', 2020), ('The God of High School', 2020), (\"Darwin's Game\", 2020), ('Our Love Has Always Been 10 Centimeters Apart.', 2017), ('Gen V - Prime Premiere', 2023), ('Sherlock: The Empty Hearse', 2014), ('Love & Other Drugs', 2010), ('Once Upon a Time... in Hollywood', 2019), ('Lift', 2024), ('Men in Black 3', 2012), ('La Haine', 1995), ('The Beekeeper', 2024), ('To Me, the One Who Loved You', 2022), (\"To Every You I've Loved Before\", 2022), ('Code 8', 2019), ('Code 8 Part II', 2024), ('Ricky Stanicky', 2024), ('Road House', 2024), ('The Gentlemen', 2019), ('Se7en', 1995), ('Saltburn', 2023), ('Violet Evergarden', 2018), ('Star Wars: Episode II –\\xa0Attack of the Clones', 2002), ('BEEF', 2023), ('Puppy Love', 2023), ('Detachment', 2011), ('Baby Reindeer', 2024), ('A Cinderella Story', 2004), ('The 40 Year Old Virgin', 2005), ('Hit Man', 2023), ('Your Place or Mine', 2023), ('Anyone But You', 2023), ('The Fall Guy', 2024), ('Dune: Part Two', 2024), ('The Idea of You', 2024), ('Kung Fu Panda 4', 2024), ('Moon Knight', 2022), ('The Moment You Fall in Love', 2016), (\"I've Always Liked You\", 2016), ('Chainsaw Man', 2022), ('BLUE LOCK', 2022), ('A Family Affair', 2024), ('ted', 2024), ('The Empire Strikes Back', 1980), ('Jujutsu Kaisen 0', 2021), (\"Groot's First Steps\", 2022), ('The Little Guy', 2022), (\"Groot's Pursuit\", 2022), ('Groot Takes a Bath', 2022), ('Magnum Opus', 2022), ('Are You My Groot?', 2023), ('Groot Noses Around', 2023), (\"Groot's Snow Day\", 2023), (\"Groot's Sweet Treat\", 2023), ('Groot and the Great Prophecy', 2023), ('Deadpool & Wolverine', 2024), ('X2', 2003), ('The Union', 2024), ('Who Framed Roger Rabbit', 1988), ('Argylle', 2024), ('Bad Boys: Ride or Die', 2024), ('Air', 2023), ('Split', 2016), ('Woman of the Hour', 2023), ('Challengers', 2024), ('DAN DA DAN: First Encounter', 2024), ('Neon Genesis Evangelion', 1995), (\"Fate/stay night: Heaven's Feel I. Presage Flower\", 2017), (\"Fate/stay night: Heaven's Feel II. Lost Butterfly\", 2019), (\"Fate/stay night: Heaven's Feel III. Spring Song\", 2020), ('Ready Player One', 2018), ('A Bronx Tale', 1993), ('Jujutsu Kaisen', 2020), ('The Equalizer 3', 2023)]\n",
      "Percentage missing: 0.2894736842105263\n"
     ]
    }
   ],
   "source": [
    "print(not_found)\n",
    "print(f\"Percentage missing: {len(not_found) / len(ratings)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Harry Potter and the Prisoner of Azkaban', 72.72727272727273, 898), ('Harry Potter and the Prisoner of Azkaban', 72.72727272727273, 2112), ('Harry Potter and the Prisoner of Azkaban', 72.72727272727273, 2499), ('Harry Potter and the Prisoner of Azkaban', 72.72727272727273, 4549), ('Harry Potter and the Prisoner of Azkaban', 72.72727272727273, 7486)]\n"
     ]
    }
   ],
   "source": [
    "from rapidfuzz import fuzz, process\n",
    "titles = filtered_ratings[\"title\"]\n",
    "\n",
    "bestMatch = process.extract(\"Harry Potter and the sorcerer's stone\", titles, scorer=fuzz.ratio)\n",
    "print(bestMatch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "def find_expected_rating(movie_id, user_ratings, sparse_matrix, topk_inds, topk_sims, movie_means, global_mean, movie_id_to_index, threshold=0.2):\n",
    "    # if the movie isn't in the dataframe it has no correlations and is therefore useless and should be ignored\n",
    "    if movie_id not in movie_id_to_index:\n",
    "        return None\n",
    "    \n",
    "    user_mean = user_ratings['Rating'].mean()\n",
    "    user_bias = user_mean - global_mean\n",
    "\n",
    "    target_ind = movie_id_to_index[movie_id]\n",
    "    neigh_inds = topk_inds[target_ind]\n",
    "    neigh_sims = topk_sims[target_ind]\n",
    "\n",
    "    valid = [movie_index_to_id[idx] in user_ratings['movieId'].values for idx in neigh_inds]\n",
    "    if sum(valid) == 0:\n",
    "        return movie_means.get(movie_id, global_mean) + user_bias\n",
    "    \n",
    "    valid_inds = neigh_inds[valid]\n",
    "    valid_sims = neigh_sims[valid]\n",
    "    valid_movie_ids = [movie_index_to_id[ind] for ind in valid_inds]\n",
    "\n",
    "    valid_sims = np.array(valid_sims)\n",
    "    valid_movie_ids = np.array(valid_movie_ids)\n",
    "    mask_thresh = valid_sims > threshold\n",
    "    if mask_thresh.sum() == 0:\n",
    "        return movie_means.get(movie_id, global_mean) + user_bias\n",
    "    \n",
    "    valid_sims = valid_sims[mask_thresh]\n",
    "    valid_movie_ids = valid_movie_ids[mask_thresh]\n",
    "\n",
    "    user_ratings_dict = dict(zip(user_ratings['movieId'], user_ratings['Rating']))\n",
    "    numerator = sum((sim**2) * (user_ratings_dict[m] - movie_means.get(m, global_mean)) for sim, m in zip(valid_sims, valid_movie_ids))\n",
    "    denominator = sum(sim**2 for sim in valid_sims)\n",
    "    prediction = movie_means.get(movie_id, global_mean) + numerator/denominator + user_bias\n",
    "    return max(0.0, min(5.0, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold: 0.0:\n",
      "Mean Absolute Error (MAE): 0.5026168567321936\n",
      "Root Mean Squared Error (RMSE): 0.6149298400470549\n",
      "Outlier Percent: 2.04%\n",
      "Number of Nones: 0\n",
      "Number of test ratings: 98\n",
      "Number of train ratings: 388\n",
      "Number of total ratings: 486\n",
      "-----------------------------------\n",
      "Threshold: 0.1:\n",
      "Mean Absolute Error (MAE): 0.5026168567321936\n",
      "Root Mean Squared Error (RMSE): 0.6149298400470549\n",
      "Outlier Percent: 2.04%\n",
      "Number of Nones: 0\n",
      "Number of test ratings: 98\n",
      "Number of train ratings: 388\n",
      "Number of total ratings: 486\n",
      "-----------------------------------\n",
      "Threshold: 0.2:\n",
      "Mean Absolute Error (MAE): 0.5203554502804412\n",
      "Root Mean Squared Error (RMSE): 0.6886340325670325\n",
      "Outlier Percent: 2.04%\n",
      "Number of Nones: 0\n",
      "Number of test ratings: 98\n",
      "Number of train ratings: 388\n",
      "Number of total ratings: 486\n",
      "-----------------------------------\n",
      "Threshold: 0.3:\n",
      "Mean Absolute Error (MAE): 0.4965124933116551\n",
      "Root Mean Squared Error (RMSE): 0.6325226145046963\n",
      "Outlier Percent: 4.08%\n",
      "Number of Nones: 0\n",
      "Number of test ratings: 98\n",
      "Number of train ratings: 388\n",
      "Number of total ratings: 486\n",
      "-----------------------------------\n",
      "Threshold: 0.4:\n",
      "Mean Absolute Error (MAE): 0.5318016302942632\n",
      "Root Mean Squared Error (RMSE): 0.6629357299817521\n",
      "Outlier Percent: 3.06%\n",
      "Number of Nones: 0\n",
      "Number of test ratings: 98\n",
      "Number of train ratings: 388\n",
      "Number of total ratings: 486\n",
      "-----------------------------------\n",
      "Threshold: 0.5:\n",
      "Mean Absolute Error (MAE): 0.5248715428374943\n",
      "Root Mean Squared Error (RMSE): 0.6497047419422769\n",
      "Outlier Percent: 1.02%\n",
      "Number of Nones: 0\n",
      "Number of test ratings: 98\n",
      "Number of train ratings: 388\n",
      "Number of total ratings: 486\n",
      "-----------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Compare each actual rating with the expected rating to evaluate the accuracy of the model\n",
    "def evaluate_predictions(train_ratings, test_ratings, sparse_matrix, topk_inds, topk_sims, movie_means, global_mean, movie_id_to_index):    \n",
    "    results = {}\n",
    "    for thresh in [0.0, 0.1, 0.2, 0.3, 0.4, 0.5]:\n",
    "        predictions = []\n",
    "        actuals = []\n",
    "        movie_ids = []\n",
    "        outliers = 0\n",
    "        Nones = 0\n",
    "        for _, row in test_ratings.iterrows():\n",
    "            movie_id = row['movieId']\n",
    "            actual_rating = row['Rating']\n",
    "            \n",
    "            expected_rating = find_expected_rating(movie_id, train_ratings, sparse_matrix, topk_inds, topk_sims, movie_means, global_mean, movie_id_to_index, threshold=thresh)\n",
    "        \n",
    "            if expected_rating is not None:\n",
    "                predictions.append(expected_rating)\n",
    "                actuals.append(actual_rating)\n",
    "                movie_ids.append(movie_id)\n",
    "\n",
    "                # Number of predictions that are drastically different from the actual rating\n",
    "                if abs(expected_rating - actual_rating) > 1.5:\n",
    "                    outliers += 1\n",
    "            else:\n",
    "                Nones += 1\n",
    "    \n",
    "        mae = mean_absolute_error(actuals, predictions) if predictions else None\n",
    "        rmse = np.sqrt(mean_squared_error(actuals, predictions)) if predictions else None\n",
    "        outlier_percent = (outliers / len(test_ratings)) * 100\n",
    "        results[thresh] = (predictions, movie_ids, mae, rmse, outlier_percent, Nones)\n",
    "\n",
    "    return results\n",
    "\n",
    "train_ratings, test_ratings = train_test_split(ratings_with_ids, test_size=0.20, random_state=1)\n",
    "results = evaluate_predictions(train_ratings, test_ratings, sparse_matrix, topk_inds, topk_sims, movie_means, global_mean, movie_id_to_index)\n",
    "\n",
    "for thresh, (predictions, titles, mae, rmse, outlier_percent, Nones) in results.items():\n",
    "    print(f\"Threshold: {thresh}:\")\n",
    "    print(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "    print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n",
    "    print(f\"Outlier Percent: {outlier_percent:.2f}%\")\n",
    "    print(f\"Number of Nones: {Nones}\")\n",
    "    print(f\"Number of test ratings: {len(test_ratings)}\")\n",
    "    print(f\"Number of train ratings: {len(train_ratings)}\")\n",
    "    print(f\"Number of total ratings: {len(ratings_with_ids)}\")\n",
    "    print(\"-----------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal Modes:\n",
      " Threshold  NumMovies      MAE  AccuracyImprovement  MovieReduction  Tradeoff\n",
      "      4000       1784 0.467770             0.087019           15655  0.000006\n",
      "      3900       1814 0.468110             0.086679           15625  0.000006\n",
      "      4100       1745 0.468997             0.085792           15694  0.000005\n",
      "      4400       1653 0.469383             0.085406           15786  0.000005\n",
      "      4300       1683 0.470331             0.084458           15756  0.000005\n",
      "All Results:\n",
      " Threshold  NumMovies      MAE  AccuracyImprovement  MovieReduction      Tradeoff\n",
      "        40      17439 0.554789             0.000000               0           NaN\n",
      "        50      15975 0.548445             0.006344            1464  4.333266e-06\n",
      "       100      12154 0.550034             0.004755            5285  8.997556e-07\n",
      "       200       9292 0.541092             0.013697            8147  1.681228e-06\n",
      "       300       7782 0.524712             0.030077            9657  3.114485e-06\n",
      "       400       6881 0.530756             0.024033           10558  2.276270e-06\n",
      "       500       6210 0.527370             0.027419           11229  2.441782e-06\n",
      "       600       5710 0.518019             0.036770           11729  3.134923e-06\n",
      "       700       5282 0.532186             0.022603           12157  1.859237e-06\n",
      "       800       4933 0.537098             0.017691           12506  1.414629e-06\n",
      "       900       4629 0.534489             0.020300           12810  1.584692e-06\n",
      "      1000       4388 0.534501             0.020288           13051  1.554494e-06\n",
      "      1100       4179 0.539384             0.015405           13260  1.161729e-06\n",
      "      1200       3971 0.538469             0.016320           13468  1.211755e-06\n",
      "      1300       3786 0.540549             0.014240           13653  1.042963e-06\n",
      "      1400       3633 0.547131             0.007658           13806  5.546721e-07\n",
      "      1500       3477 0.547131             0.007658           13962  5.484746e-07\n",
      "      1600       3341 0.562471            -0.007683           14098 -5.449371e-07\n",
      "      1700       3217 0.556165            -0.001376           14222 -9.673453e-08\n",
      "      1800       3092 0.564182            -0.009393           14347 -6.546814e-07\n",
      "      1900       2988 0.567687            -0.012898           14451 -8.925119e-07\n",
      "      2000       2882 0.567687            -0.012898           14557 -8.860129e-07\n",
      "      2100       2811 0.567643            -0.012854           14628 -8.787108e-07\n",
      "      2200       2710 0.573809            -0.019020           14729 -1.291340e-06\n",
      "      2300       2631 0.573485            -0.018696           14808 -1.262552e-06\n",
      "      2400       2551 0.573208            -0.018420           14888 -1.237207e-06\n",
      "      2500       2488 0.534814             0.019975           14951  1.336002e-06\n",
      "      2600       2435 0.535348             0.019441           15004  1.295737e-06\n",
      "      2700       2368 0.531632             0.023157           15071  1.536495e-06\n",
      "      2800       2311 0.531632             0.023157           15128  1.530706e-06\n",
      "      2900       2259 0.538119             0.016670           15180  1.098162e-06\n",
      "      3000       2201 0.537313             0.017476           15238  1.146860e-06\n",
      "      3100       2142 0.519077             0.035712           15297  2.334577e-06\n",
      "      3200       2087 0.489563             0.065226           15352  4.248687e-06\n",
      "      3300       2042 0.490907             0.063882           15397  4.149008e-06\n",
      "      3400       1993 0.491451             0.063338           15446  4.100625e-06\n",
      "      3500       1947 0.492371             0.062418           15492  4.029031e-06\n",
      "      3600       1910 0.493529             0.061260           15529  3.944884e-06\n",
      "      3700       1870 0.493184             0.061605           15569  3.956923e-06\n",
      "      3800       1838 0.493329             0.061460           15601  3.939467e-06\n",
      "      3900       1814 0.468110             0.086679           15625  5.547452e-06\n",
      "      4000       1784 0.467770             0.087019           15655  5.558512e-06\n",
      "      4100       1745 0.468997             0.085792           15694  5.466540e-06\n",
      "      4200       1710 0.470879             0.083910           15729  5.334704e-06\n",
      "      4300       1683 0.470331             0.084458           15756  5.360350e-06\n",
      "      4400       1653 0.469383             0.085406           15786  5.410228e-06\n",
      "      4500       1622 0.470190             0.084599           15817  5.348599e-06\n"
     ]
    }
   ],
   "source": [
    "# Increasing the minimum number of ratings required increases accuracy but reduces the number of movies\n",
    "# Find the optimal threshold to balance accuracy and number of movies\n",
    "def evaluate_for_threshold(threshold):\n",
    "    ratings_per_movie = all_ratings.groupby('movieId').size()\n",
    "    accepted_movies = ratings_per_movie[ratings_per_movie >= threshold].index\n",
    "    filtered_ratings = all_ratings[all_ratings['movieId'].isin(accepted_movies)]\n",
    "    num_movies = filtered_ratings['movieId'].nunique()\n",
    "    \n",
    "    user_ids = filtered_ratings['userId'].astype('category').cat.codes\n",
    "    title_ids = filtered_ratings['title'].astype('category').cat.codes\n",
    "    sparse_matrix = coo_matrix((filtered_ratings['rating'], (user_ids, title_ids))).tocsr()\n",
    "    similarity_matrix = cosine_similarity(sparse_matrix.T, dense_output=False)\n",
    "    titles = filtered_ratings['title'].astype('category').cat.categories\n",
    "    movie_similarity_df = pd.DataFrame(similarity_matrix.toarray(), index=titles, columns=titles)\n",
    "\n",
    "    # Evaluate predictions\n",
    "    predictions, actuals, titles, mae, rmse, outlier_percent, Nones = evaluate_predictions(train_ratings, test_ratings, movie_similarity_df, global_mean, movie_means)\n",
    "    return num_movies, mae\n",
    "\n",
    "thresholds_0_100 = range(40, 60, 10)\n",
    "thresholds_100_1000 = range(100, 4501, 100)\n",
    "\n",
    "# Combine the two ranges\n",
    "thresholds = list(thresholds_0_100) + list(thresholds_100_1000)\n",
    "results = []\n",
    "\n",
    "for threshold in thresholds:\n",
    "    num_movies, mae = evaluate_for_threshold(threshold)\n",
    "    if mae is not None:\n",
    "        results.append((threshold, num_movies, mae))\n",
    "\n",
    "#Analyze results to select modes\n",
    "results_df = pd.DataFrame(results, columns=['Threshold', 'NumMovies', 'MAE'])\n",
    "results_df['AccuracyImprovement'] = results_df['MAE'].iloc[0] - results_df['MAE']\n",
    "results_df['MovieReduction'] = results_df['NumMovies'].iloc[0] - results_df['NumMovies']\n",
    "results_df['Tradeoff'] = results_df['AccuracyImprovement'] / results_df['MovieReduction']\n",
    "\n",
    "# Select top 5 thresholds based on tradeoff\n",
    "top_thresholds = results_df.sort_values('Tradeoff', ascending=False).head(5)\n",
    "print(\"Optimal Modes:\")\n",
    "print(top_thresholds.to_string(index=False))\n",
    "\n",
    "# Display all results\n",
    "print(\"All Results:\")\n",
    "print(results_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " movieId  Expected Rating  Popularity                        title                         genres  year\n",
      "    2300              5.0        7088                The Producers                         Comedy  1968\n",
      "     123              5.0        3534            Chungking Express          Drama|Mystery|Romance  1994\n",
      "    7486              5.0         658               Happy Together                  Drama|Romance  1997\n",
      "    1757              5.0         955                Fallen Angels                  Drama|Romance  1995\n",
      "   71438              5.0         287                Still Walking                          Drama  2008\n",
      "   89759              5.0        2476                Separation, A                          Drama  2011\n",
      "  103984              5.0        1296             The Great Beauty                   Comedy|Drama  2013\n",
      "  163809              4.5        1397         Over the Garden Wall      Adventure|Animation|Drama  2013\n",
      "    4237              4.5         367             The Gleaners & I                    Documentary  2000\n",
      "  118896              4.5         791                        Mommy                          Drama  2014\n",
      "   73808              4.5         960                   The Chaser           Crime|Drama|Thriller  2008\n",
      "  117533              4.5        2306                  Citizenfour                    Documentary  2014\n",
      "    1859              4.5         651              Taste of Cherry                          Drama  1997\n",
      "   76091              4.5        1051                       Mother   Crime|Drama|Mystery|Thriller  2009\n",
      "    5794              4.5         279                    Good Work                          Drama  1999\n",
      "  189885              4.5         746                   The Guilty                       Thriller  2018\n",
      "  128620              4.5         937                     Victoria            Crime|Drama|Romance  2015\n",
      "  198185              4.5        1140                   Twin Peaks                  Drama|Mystery  1989\n",
      "  169906              4.5        1137                 The Night Of                    Crime|Drama  2016\n",
      "  175813              4.5         433                Force Majeure                   Comedy|Drama  2014\n",
      "  159817              4.5        2948                 Planet Earth                    Documentary  2006\n",
      "  171011              4.5        1956              Planet Earth II                    Documentary  2016\n",
      "   42632              4.5        1983               Lady Vengeance   Crime|Drama|Mystery|Thriller  2005\n",
      "     101              4.5        5211                Bottle Rocket Adventure|Comedy|Crime|Romance  1996\n",
      "    4642              4.5        3000    Hedwig and the Angry Inch           Comedy|Drama|Musical  2000\n",
      "  170705              4.5        2811             Band of Brothers               Action|Drama|War  2001\n",
      "   85774              4.5        2190                        Senna                    Documentary  2010\n",
      "    2391              4.5        7098               Simple Plan, A           Crime|Drama|Thriller  1998\n",
      "    5258              4.5         354            George Washington                          Drama  2000\n",
      "  158972              4.5         658                 Toni Erdmann                          Drama  2016\n",
      "  141890              4.5        1049          Beasts of No Nation                      Drama|War  2015\n",
      "     527              4.5       73849             Schindler's List                      Drama|War  1993\n",
      "    1449              4.5        6433          Waiting for Guffman                         Comedy  1996\n",
      "    3317              4.5        7169                  Wonder Boys                   Comedy|Drama  2000\n",
      "    2301              4.5        4948 History of the World: Part I                 Comedy|Musical  1981\n",
      "    5782              4.5        4835             The Professional          Action|Drama|Thriller  1981\n",
      "  173197              4.5         861                   The Square                          Drama  2017\n",
      "    1916              4.5        3592                  Buffalo '66                  Drama|Romance  1998\n",
      "  166291              4.5         893               A Silent Voice        Animation|Drama|Romance  2016\n",
      "  166024              4.5        3080                     Whiplash             (no genres listed)  2013\n",
      "Rating Interval\n",
      "0-1      12\n",
      "1-2     164\n",
      "2-3    1890\n",
      "3-4    7890\n",
      "4-5    1695\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def recommend_movies(user_ratings, sparse_matrix, startYear, endYear, topk_inds, topk_sims, movie_means, global_mean, movie_index_to_id):\n",
    "    ratings_count = all_ratings.groupby('movieId').size()\n",
    "    already_rated = set(user_ratings['movieId'])\n",
    "    \n",
    "    # Pre-compute user statistics\n",
    "    user_mean = user_ratings['Rating'].mean()\n",
    "    user_bias = user_mean - global_mean\n",
    "    user_ratings_dict = dict(zip(user_ratings['movieId'], user_ratings['Rating']))\n",
    "    \n",
    "    # Get all candidate movies\n",
    "    all_movie_ids = list(movie_index_to_id.values())\n",
    "    candidate_ids = [mid for mid in all_movie_ids if mid not in already_rated]\n",
    "    \n",
    "    # Vectorized prediction\n",
    "    predictions = []\n",
    "    for movie_id in candidate_ids:\n",
    "        if movie_id not in movie_id_to_index:\n",
    "            continue\n",
    "            \n",
    "        target_ind = movie_id_to_index[movie_id]\n",
    "        neigh_inds = topk_inds[target_ind]\n",
    "        neigh_sims = topk_sims[target_ind]\n",
    "        \n",
    "        # Find which neighbors the user has rated\n",
    "        neighbor_movie_ids = [movie_index_to_id[idx] for idx in neigh_inds]\n",
    "        rated_mask = np.array([mid in user_ratings_dict for mid in neighbor_movie_ids])\n",
    "        \n",
    "        if not rated_mask.any():\n",
    "            pred = movie_means.get(movie_id, global_mean) + user_bias\n",
    "        else:\n",
    "            valid_sims = neigh_sims[rated_mask]\n",
    "            valid_movie_ids = np.array(neighbor_movie_ids)[rated_mask]\n",
    "            \n",
    "            # Apply threshold\n",
    "            thresh_mask = valid_sims > 0.2\n",
    "            if not thresh_mask.any():\n",
    "                pred = movie_means.get(movie_id, global_mean) + user_bias\n",
    "            else:\n",
    "                valid_sims = valid_sims[thresh_mask]\n",
    "                valid_movie_ids = valid_movie_ids[thresh_mask]\n",
    "                \n",
    "                # Vectorized calculation\n",
    "                user_ratings_arr = np.array([user_ratings_dict[m] for m in valid_movie_ids])\n",
    "                movie_means_arr = np.array([movie_means.get(m, global_mean) for m in valid_movie_ids])\n",
    "                \n",
    "                numerator = np.sum((valid_sims**2) * (user_ratings_arr - movie_means_arr))\n",
    "                denominator = np.sum(valid_sims**2)\n",
    "                pred = movie_means.get(movie_id, global_mean) + numerator/denominator + user_bias\n",
    "                pred = max(0.0, min(5.0, pred))\n",
    "        \n",
    "        predictions.append((movie_id, pred, ratings_count.get(movie_id, 0)))\n",
    "    \n",
    "    # Sort and create DataFrame\n",
    "    predictions.sort(key=lambda x: (x[1], x[2]), reverse=True)\n",
    "    recommendations = pd.DataFrame(predictions, columns=['movieId', 'Expected Rating', 'Popularity'])\n",
    "    \n",
    "    recommendations = recommendations.merge(\n",
    "        filtered_ratings[['movieId', 'title', 'genres', 'year']].drop_duplicates(), \n",
    "        on='movieId', how='left'\n",
    "    )\n",
    "    recommendations = recommendations[recommendations['year'].between(startYear, endYear, inclusive='both')]\n",
    "    recommendations['Expected Rating'] = (recommendations['Expected Rating'] * 2).round() / 2\n",
    "    \n",
    "    return recommendations\n",
    "\n",
    "recommendation_list = recommend_movies(ratings_with_ids, sparse_matrix, 1900, 2024, topk_inds, topk_sims, movie_means, global_mean, movie_index_to_id)\n",
    "\n",
    "print(recommendation_list.head(40).to_string(index=False))\n",
    "\n",
    "bins = [0, 1, 2, 3, 4, 5]\n",
    "labels = ['0-1', '1-2', '2-3', '3-4', '4-5']\n",
    "recommendation_list['Rating Interval'] = pd.cut(recommendation_list['Expected Rating'], bins=bins, labels=labels, right=False)\n",
    "\n",
    "rating_distribution = recommendation_list['Rating Interval'].value_counts().sort_index()\n",
    "print(rating_distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " movieId  Expected Rating  Popularity                        title                         genres  year\n",
      "    2300              5.0        7088                The Producers                         Comedy  1968\n",
      "     123              5.0        3534            Chungking Express          Drama|Mystery|Romance  1994\n",
      "    7486              5.0         658               Happy Together                  Drama|Romance  1997\n",
      "    1757              5.0         955                Fallen Angels                  Drama|Romance  1995\n",
      "   71438              5.0         287                Still Walking                          Drama  2008\n",
      "   89759              5.0        2476                Separation, A                          Drama  2011\n",
      "  103984              5.0        1296             The Great Beauty                   Comedy|Drama  2013\n",
      "  163809              4.5        1397         Over the Garden Wall      Adventure|Animation|Drama  2013\n",
      "    4237              4.5         367             The Gleaners & I                    Documentary  2000\n",
      "  118896              4.5         791                        Mommy                          Drama  2014\n",
      "   73808              4.5         960                   The Chaser           Crime|Drama|Thriller  2008\n",
      "  117533              4.5        2306                  Citizenfour                    Documentary  2014\n",
      "    1859              4.5         651              Taste of Cherry                          Drama  1997\n",
      "   76091              4.5        1051                       Mother   Crime|Drama|Mystery|Thriller  2009\n",
      "    5794              4.5         279                    Good Work                          Drama  1999\n",
      "  189885              4.5         746                   The Guilty                       Thriller  2018\n",
      "  128620              4.5         937                     Victoria            Crime|Drama|Romance  2015\n",
      "  198185              4.5        1140                   Twin Peaks                  Drama|Mystery  1989\n",
      "  169906              4.5        1137                 The Night Of                    Crime|Drama  2016\n",
      "  175813              4.5         433                Force Majeure                   Comedy|Drama  2014\n",
      "  159817              4.5        2948                 Planet Earth                    Documentary  2006\n",
      "  171011              4.5        1956              Planet Earth II                    Documentary  2016\n",
      "   42632              4.5        1983               Lady Vengeance   Crime|Drama|Mystery|Thriller  2005\n",
      "     101              4.5        5211                Bottle Rocket Adventure|Comedy|Crime|Romance  1996\n",
      "    4642              4.5        3000    Hedwig and the Angry Inch           Comedy|Drama|Musical  2000\n",
      "  170705              4.5        2811             Band of Brothers               Action|Drama|War  2001\n",
      "   85774              4.5        2190                        Senna                    Documentary  2010\n",
      "    2391              4.5        7098               Simple Plan, A           Crime|Drama|Thriller  1998\n",
      "    5258              4.5         354            George Washington                          Drama  2000\n",
      "  158972              4.5         658                 Toni Erdmann                          Drama  2016\n",
      "  141890              4.5        1049          Beasts of No Nation                      Drama|War  2015\n",
      "     527              4.5       73849             Schindler's List                      Drama|War  1993\n",
      "    1449              4.5        6433          Waiting for Guffman                         Comedy  1996\n",
      "    3317              4.5        7169                  Wonder Boys                   Comedy|Drama  2000\n",
      "    2301              4.5        4948 History of the World: Part I                 Comedy|Musical  1981\n",
      "    5782              4.5        4835             The Professional          Action|Drama|Thriller  1981\n",
      "  173197              4.5         861                   The Square                          Drama  2017\n",
      "    1916              4.5        3592                  Buffalo '66                  Drama|Romance  1998\n",
      "  166291              4.5         893               A Silent Voice        Animation|Drama|Romance  2016\n",
      "  166024              4.5        3080                     Whiplash             (no genres listed)  2013\n",
      "Rating Interval\n",
      "0-1      12\n",
      "1-2     164\n",
      "2-3    1890\n",
      "3-4    7890\n",
      "4-5    1695\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def recommend_movies(user_ratings, sparse_matrix, startYear, endYear, topk_inds, topk_sims, movie_means, global_mean, movie_index_to_id):\n",
    "    recommendations = []\n",
    "    ratings_count = all_ratings.groupby('movieId').size()\n",
    "    already_rated = set(user_ratings['movieId'])\n",
    "\n",
    "\n",
    "    # For every movie in the similarity matrix, calculate the expected rating for the user if they haven't seen it\n",
    "    for movie_id in movie_index_to_id.values():\n",
    "        if movie_id not in already_rated:\n",
    "            expected_rating = find_expected_rating(movie_id, user_ratings, sparse_matrix, topk_inds, topk_sims, movie_means, global_mean, {v: k for k, v in movie_index_to_id.items()}, threshold=0.2)\n",
    "            if expected_rating is not None:\n",
    "                num_ratings = ratings_count.get(movie_id, 0)\n",
    "\n",
    "                recommendations.append((movie_id, expected_rating, num_ratings))\n",
    "\n",
    "    # Sort the recommendations by expected rating and then by popularity\n",
    "    recommendations.sort(key=lambda x: (x[1], x[2]), reverse=True)\n",
    "    recommendations = pd.DataFrame(recommendations, columns=['movieId', 'Expected Rating', 'Popularity'])\n",
    "\n",
    "    recommendations = recommendations.merge(filtered_ratings[['movieId', 'title', 'genres', 'year']].drop_duplicates(), on='movieId', how='left')\n",
    "    recommendations = recommendations[recommendations['year'].between(startYear, endYear, inclusive='both')]\n",
    "    recommendations['Expected Rating'] = (recommendations['Expected Rating'] * 2).round() / 2\n",
    "    \n",
    "\n",
    "    return recommendations\n",
    "\n",
    "recommendation_list = recommend_movies(ratings_with_ids, sparse_matrix, 1900, 2024, topk_inds, topk_sims, movie_means, global_mean, movie_index_to_id)\n",
    "\n",
    "print(recommendation_list.head(40).to_string(index=False))\n",
    "\n",
    "bins = [0, 1, 2, 3, 4, 5]\n",
    "labels = ['0-1', '1-2', '2-3', '3-4', '4-5']\n",
    "recommendation_list['Rating Interval'] = pd.cut(recommendation_list['Expected Rating'], bins=bins, labels=labels, right=False)\n",
    "\n",
    "rating_distribution = recommendation_list['Rating Interval'].value_counts().sort_index()\n",
    "print(rating_distribution)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
