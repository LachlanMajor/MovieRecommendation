{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import re\n",
    "\n",
    "# User ratings from letterboxd csv \n",
    "ratings = pd.read_csv(\"ratings.csv\")\n",
    "ratings = ratings.drop(columns=['Date', 'Letterboxd URI'])\n",
    "\n",
    "# Collection of movie titles with their genres\n",
    "movies = pd.read_csv(\"movies.csv\")\n",
    "# Remove (year) from titles\n",
    "movies[['title', 'year']] = movies['title'].str.extract(r'^(.*)\\s\\((\\d{4})\\)$')\n",
    "movies['year'] = pd.to_numeric(movies['year'], errors='coerce')\n",
    "movies['year'] = movies['year'].fillna(0).astype(int)\n",
    "# Remove Nan titles\n",
    "movies= movies.dropna(subset=['title']).reset_index(drop=True)\n",
    "\n",
    "# Colletion of ratings to be used in the correlation matrix.\n",
    "all_ratings = pd.read_csv(\"allratings.csv\", index_col=False)\n",
    "all_ratings = all_ratings.drop(columns=['timestamp'])\n",
    "all_ratings = all_ratings.dropna(subset=['userId', 'movieId', 'rating'])\n",
    "# Merge movies into all_ratings to have title, genres, and year\n",
    "all_ratings = pd.merge(all_ratings, movies)\n",
    "# Remove anything in brackets in the title for things like foreign films and the original title\n",
    "all_ratings['title'] = all_ratings['title'].str.replace(r'\\s*\\(.*?\\)', '', regex=True)\n",
    "\n",
    "# Any title with The, A, or An has it moved to the front\n",
    "def move_article_to_front(title):\n",
    "    match = re.match(r'^(.*?),\\s*(The|A|An)$', title, re.IGNORECASE)\n",
    "    if match:\n",
    "        rest_of_title, article = match.groups()\n",
    "        return f\"{article} {rest_of_title}\"\n",
    "    return title\n",
    "\n",
    "ratings['Name'] = ratings['Name'].apply(move_article_to_front)\n",
    "all_ratings['title'] = all_ratings['title'].apply(move_article_to_front)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movies: 772\n"
     ]
    }
   ],
   "source": [
    "# Limit the included movies to movies with a minimum number of ratings\n",
    "ratings_per_movie = all_ratings.groupby('movieId').size()\n",
    "accepted_movies = ratings_per_movie[ratings_per_movie >= 10000].index\n",
    "filtered_ratings = all_ratings[all_ratings['movieId'].isin(accepted_movies)]\n",
    "num_movies = filtered_ratings['movieId'].nunique()\n",
    "print(f\"Movies: {num_movies}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import coo_matrix\n",
    "\n",
    "\n",
    "def calculate_similarity(sparse_matrix):\n",
    "    # Calculate the cosine similarity between movies. Transpose the matrix to find item-item similarity instead of user-user\n",
    "    similarity = cosine_similarity(sparse_matrix.T, dense_output=False)\n",
    "    \n",
    "    # Calculate the signifance of the correlation based on the number of ratings. i.e more ratings should mean more impact on the correlation calculation\n",
    "    n_ratings = (sparse_matrix != 0).sum(axis=0)\n",
    "    min_ratings = 1000\n",
    "    significance_matrix = n_ratings.T.dot(n_ratings) / (n_ratings.T.dot(n_ratings) + min_ratings)\n",
    "    \n",
    "    return similarity.multiply(significance_matrix)\n",
    "\n",
    "# Make a matrix of all movie correlations\n",
    "def make_matrix(fitlered_ratings):\n",
    "    global_mean = fitlered_ratings['rating'].mean()\n",
    "    \n",
    "    movie_means = filtered_ratings.groupby('title')['rating'].mean().to_dict()\n",
    "    \n",
    "    user_ids = filtered_ratings['userId'].astype('category').cat.codes\n",
    "    title_ids = filtered_ratings['title'].astype('category').cat.codes\n",
    "    rating_values = filtered_ratings['rating']\n",
    "    \n",
    "    # Sparse matrix made with coo_matrix to include only non 0 values, therefore saving space and time\n",
    "    sparse_matrix = coo_matrix((rating_values, (user_ids, title_ids))).tocsr()\n",
    "    \n",
    "    movie_similarity = calculate_similarity(sparse_matrix)\n",
    "    \n",
    "    titles = filtered_ratings['title'].astype('category').cat.categories\n",
    "    movie_similarity_df = pd.DataFrame(\n",
    "        movie_similarity.toarray(),\n",
    "        index=titles,\n",
    "        columns=titles\n",
    "    )\n",
    "    \n",
    "    return movie_similarity_df, global_mean, movie_means\n",
    "\n",
    "movie_similarity_df, global_mean, movie_means = make_matrix(filtered_ratings)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from rapidfuzz import process, fuzz\n",
    "from difflib import ndiff\n",
    "\n",
    "\n",
    "# Some movie titles differ slightly in the dataset so extremly similar titles are matched to find movies with different titles\n",
    "def replace_titles(user_df, movie_similarity_df, threshold=95):\n",
    "    title_map = {}\n",
    "    \n",
    "    dataset_titles = movie_similarity_df.columns\n",
    "    # Iterate over user rated movies\n",
    "    for i, user_movie in enumerate(user_df['Name']):\n",
    "        \n",
    "        # Skip if the movie is already in the dataset\n",
    "        if user_movie in dataset_titles:\n",
    "            continue\n",
    "\n",
    "        # Find the best match in the dataset\n",
    "        match, score, index = process.extractOne(\n",
    "            user_movie,\n",
    "            dataset_titles,\n",
    "            scorer=fuzz.token_sort_ratio\n",
    "        )\n",
    "        \n",
    "        # If the similarity score isn't high enough, skip\n",
    "        if score >= threshold:\n",
    "            # If the match is already in the user rating, it is a different movie so skip it\n",
    "            if match not in user_df['Name'].values:\n",
    "                #print(f\"Matched '{user_movie}' with '{match}'\")\n",
    "                user_df.at[i, 'Name'] = match\n",
    "\n",
    "    return user_df\n",
    "\n",
    "ratings = replace_titles(ratings, movie_similarity_df, threshold=90)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of not found movies: 162\n",
      "['Glass Onion', 'Avengers: Infinity War', 'Spider-Man: Homecoming', \"Harry Potter and the Philosopher's Stone\", 'A Silent Voice: The Movie', 'Entergalactic', 'Devilman Crybaby', 'Demon Slayer -Kimetsu no Yaiba- The Movie: Mugen Train', 'Cyberpunk: Edgerunners', 'The Last: Naruto the Movie', 'Your Lie in April', 'Hotarubi no Mori e', 'AnoHana: The Flower We Saw That Day', 'Words Bubble Up Like Soda Pop', 'Violet Evergarden: Eternity and the Auto Memory Doll', 'Violet Evergarden: The Movie', 'Demon Slayer: Kimetsu no Yaiba', 'Tokyo Ghoul', 'Bakemonogatari', 'Kotaro Lives Alone', 'Flowers of Evil', 'Great Pretender', 'Death Parade', 'Blue Period', 'Wotakoi: Love Is Hard for Otaku', 'Grand Blue Dreaming', 'Orange', 'Blue Spring Ride', 'Horimiya', 'Vinland Saga', 'Star Wars', 'Black Mirror: Striking Vipers', 'Black Mirror: The Entire History of You', 'Avengers: Endgame', 'Black Mirror: Fifteen Million Merits', 'Sherlock: A Study in Pink', 'Sherlock: The Blind Banker', 'Sherlock: The Great Game', 'Sherlock: A Scandal in Belgravia', 'Meet Cute', \"Komi Can't Communicate\", 'Toradora!', 'DARLING in the FRANXX', 'John Wick: Chapter 2', 'Night Teeth', 'The Kissing Booth 3', \"Kuroko's Basketball the Movie: Last Game\", \"He's All That\", 'The Perfect Date', 'Fatherhood', 'Return of the Jedi', 'Black Mirror: The National Anthem', 'Black Mirror: Be Right Back', 'You Are So Not Invited to My Bat Mitzvah', 'Black Mirror: White Bear', 'The School for Good and Evil', 'Spider-Man: Far From Home', 'Black Mirror: The Waldo Moment', 'Black Mirror: White Christmas', 'The Texas Chain Saw Massacre', 'Black Mirror: Nosedive', 'Black Mirror: Playtest', 'Black Mirror: Shut Up and Dance', '(500) Days of Summer', 'Gone in Sixty Seconds', 'Star Wars: The Force Awakens', 'Sherlock: The Hounds of Baskerville', 'Sherlock: The Reichenbach Fall', 'Teenage Mutant Ninja Turtles: We Wish You a Turtle Christmas', 'Thingu', 'Hawkeye', 'Cross Road', 'Rascal Does Not Dream of Bunny Girl Senpai', \"SHIMONETA: A Boring World Where the Concept of Dirty Jokes Doesn't Exist\", 'ERASED', 'Domestic Girlfriend', 'No Game No Life', 'Tower of God', 'The Pet Girl of Sakurasou', 'The Future Diary', 'Plastic Memories', \"Masamune-kun's Revenge\", 'How Heavy Are the Dumbbells You Lift?', 'Akame ga Kill!', 'Handa-kun', 'Classroom of the Elite', 'Charlotte', 'GAMERS!', 'Oreshura', 'Cautious Hero: The Hero Is Overpowered but Overly Cautious', 'Yamada-kun and the Seven Witches', 'Golden Time', 'AHO-GIRL', 'Chivalry of a Failed Knight', 'Just Because!', 'ORESUKI Are you the only one who loves me?', 'Campione!', 'TONIKAWA: Over the Moon for You', 'The God of High School', \"Darwin's Game\", 'Our Love Has Always Been 10 Centimeters Apart.', 'Gen V - Prime Premiere', 'Sherlock: The Empty Hearse', 'Love & Other Drugs', 'Lift', 'Men in Black 3', 'La Haine', 'The Beekeeper', 'To Me, the One Who Loved You', \"To Every You I've Loved Before\", 'Code 8', 'Code 8 Part II', 'Ricky Stanicky', 'Se7en', 'Saltburn', 'Violet Evergarden', 'BEEF', 'Puppy Love', 'Detachment', 'Baby Reindeer', 'The 40 Year Old Virgin', 'Hit Man', 'Your Place or Mine', 'Anyone But You', 'The Fall Guy', 'Dune: Part Two', 'The Idea of You', 'Kung Fu Panda 4', 'Moon Knight', 'The Moment You Fall in Love', \"I've Always Liked You\", 'Chainsaw Man', 'BLUE LOCK', 'A Family Affair', 'ted', 'The Empire Strikes Back', 'Jujutsu Kaisen 0', \"Groot's First Steps\", 'The Little Guy', \"Groot's Pursuit\", 'Groot Takes a Bath', 'Magnum Opus', 'Are You My Groot?', 'Groot Noses Around', \"Groot's Snow Day\", \"Groot's Sweet Treat\", 'Groot and the Great Prophecy', 'Deadpool & Wolverine', 'X2', 'The Union', 'Argylle', 'Bad Boys: Ride or Die', 'Woman of the Hour', 'Challengers', 'DAN DA DAN: First Encounter', 'Neon Genesis Evangelion', \"Fate/stay night: Heaven's Feel I. Presage Flower\", \"Fate/stay night: Heaven's Feel II. Lost Butterfly\", \"Fate/stay night: Heaven's Feel III. Spring Song\", 'Ready Player One', 'Jujutsu Kaisen', 'The Equalizer 3']\n"
     ]
    }
   ],
   "source": [
    "not_found = []\n",
    "\n",
    "# Iterate through each movie in the ratings DataFrame\n",
    "for movie in ratings['Name']:\n",
    "    # Check if the movie exists in the all_ratings DataFrame\n",
    "    if movie not in movie_similarity_df.index:\n",
    "        not_found.append(movie)\n",
    "\n",
    "print(f\"Number of not found movies: {len(not_found)}\")\n",
    "print(not_found)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "def find_expected_rating(title, user_ratings, movie_similarity_df, global_mean, movie_means):\n",
    "    # if the movie isn't in the dataframe it has no correlations and is therefore useless and should be ignored\n",
    "    if title not in movie_similarity_df.index:\n",
    "        return None\n",
    "    \n",
    "    # Don't include the movie in the similarities\n",
    "    similarities = movie_similarity_df[title].drop(title)\n",
    "    \n",
    "    movie_ratings = user_ratings.set_index('Name')['Rating']\n",
    "    \n",
    "    # Similarities between movies the user hasn't seen shouldn't impact the expected score\n",
    "    valid_similarities = similarities[similarities.index.isin(movie_ratings.index)]\n",
    "    \n",
    "    # If they haven't seen anything just return the average rating of the movie\n",
    "    if len(valid_similarities) == 0:\n",
    "        return movie_means.get(title, global_mean)\n",
    "    \n",
    "    valid_ratings = movie_ratings[valid_similarities.index]\n",
    "    \n",
    "    numerator = 0\n",
    "    denominator = 0\n",
    "    \n",
    "    # Calculate for each movie, how far from the average the user's rating is\n",
    "    for movie, similarity in valid_similarities.items():\n",
    "        if similarity > 0.2:\n",
    "            rating_deviation = valid_ratings[movie] - movie_means.get(movie, global_mean)\n",
    "            # Multiply with similarity so the more similar movies have a greater impact on the overall expected deviation\n",
    "            # Use squared similarity so higher similarity has even greater impact\n",
    "            numerator += (similarity**2) * rating_deviation\n",
    "            denominator += abs(similarity**2)\n",
    "    \n",
    "    if denominator == 0:\n",
    "        return movie_means.get(title, global_mean)\n",
    "    \n",
    "    # Based on the users weighted deviation above, predict the users rating for the movie\n",
    "    prediction = movie_means.get(title, global_mean) + (numerator / denominator)\n",
    "    \n",
    "    if isinstance(prediction, pd.Series):\n",
    "        prediction = prediction.iloc[0]\n",
    "    return max(0.0, min(5.0, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE): 0.40352730634707223\n",
      "Root Mean Squared Error (RMSE): 0.5639414693152539\n",
      "Outlier Percent: 0.73%\n",
      "Number of Nones: 93\n",
      "Number of test ratings: 137\n",
      "Number of train ratings: 547\n",
      "Number of total ratings: 684\n"
     ]
    }
   ],
   "source": [
    "# Compare each actual rating with the expected rating to evaluate the accuracy of the model\n",
    "def evaluate_predictions(train_ratings, test_ratings, movie_similarity_df, global_mean, movie_means):\n",
    "    predictions = []\n",
    "    actuals = []\n",
    "    titles = []\n",
    "    outliers = 0\n",
    "    Nones = 0\n",
    "    \n",
    "    for index, row in test_ratings.iterrows():\n",
    "        title = row['Name']\n",
    "        actual_rating = row['Rating']\n",
    "        \n",
    "        expected_rating = find_expected_rating(title, train_ratings, movie_similarity_df, global_mean, movie_means)\n",
    "        \n",
    "        if expected_rating is not None:\n",
    "            predictions.append(expected_rating)\n",
    "            actuals.append(actual_rating)\n",
    "            titles.append(title)\n",
    "\n",
    "            # Number of predictions that are drastically different from the actual rating\n",
    "            if abs(expected_rating - actual_rating) > 1.5:\n",
    "                outliers += 1\n",
    "        else:\n",
    "            Nones += 1\n",
    "    \n",
    "    mae = mean_absolute_error(actuals, predictions) if predictions else None\n",
    "    rmse = np.sqrt(mean_squared_error(actuals, predictions)) if predictions else None\n",
    "    outlier_percent = (outliers / len(test_ratings)) * 100\n",
    "    \n",
    "    return predictions, actuals, titles, mae, rmse, outlier_percent, Nones\n",
    "\n",
    "train_ratings, test_ratings = train_test_split(ratings, test_size=0.20, random_state=1)\n",
    "predictions, actuals, titles, mae, rmse, outlier_percent, Nones = evaluate_predictions(train_ratings, test_ratings, movie_similarity_df, global_mean, movie_means)\n",
    "\n",
    "print(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n",
    "print(f\"Outlier Percent: {outlier_percent:.2f}%\")\n",
    "print(f\"Number of Nones: {Nones}\")\n",
    "print(f\"Number of test ratings: {len(test_ratings)}\")\n",
    "print(f\"Number of train ratings: {len(train_ratings)}\")\n",
    "print(f\"Number of total ratings: {len(ratings)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal Modes:\n",
      " Threshold  NumMovies      MAE  AccuracyImprovement  MovieReduction  Tradeoff\n",
      "      4000       1784 0.467770             0.087019           15655  0.000006\n",
      "      3900       1814 0.468110             0.086679           15625  0.000006\n",
      "      4100       1745 0.468997             0.085792           15694  0.000005\n",
      "      4400       1653 0.469383             0.085406           15786  0.000005\n",
      "      4300       1683 0.470331             0.084458           15756  0.000005\n",
      "All Results:\n",
      " Threshold  NumMovies      MAE  AccuracyImprovement  MovieReduction      Tradeoff\n",
      "        40      17439 0.554789             0.000000               0           NaN\n",
      "        50      15975 0.548445             0.006344            1464  4.333266e-06\n",
      "       100      12154 0.550034             0.004755            5285  8.997556e-07\n",
      "       200       9292 0.541092             0.013697            8147  1.681228e-06\n",
      "       300       7782 0.524712             0.030077            9657  3.114485e-06\n",
      "       400       6881 0.530756             0.024033           10558  2.276270e-06\n",
      "       500       6210 0.527370             0.027419           11229  2.441782e-06\n",
      "       600       5710 0.518019             0.036770           11729  3.134923e-06\n",
      "       700       5282 0.532186             0.022603           12157  1.859237e-06\n",
      "       800       4933 0.537098             0.017691           12506  1.414629e-06\n",
      "       900       4629 0.534489             0.020300           12810  1.584692e-06\n",
      "      1000       4388 0.534501             0.020288           13051  1.554494e-06\n",
      "      1100       4179 0.539384             0.015405           13260  1.161729e-06\n",
      "      1200       3971 0.538469             0.016320           13468  1.211755e-06\n",
      "      1300       3786 0.540549             0.014240           13653  1.042963e-06\n",
      "      1400       3633 0.547131             0.007658           13806  5.546721e-07\n",
      "      1500       3477 0.547131             0.007658           13962  5.484746e-07\n",
      "      1600       3341 0.562471            -0.007683           14098 -5.449371e-07\n",
      "      1700       3217 0.556165            -0.001376           14222 -9.673453e-08\n",
      "      1800       3092 0.564182            -0.009393           14347 -6.546814e-07\n",
      "      1900       2988 0.567687            -0.012898           14451 -8.925119e-07\n",
      "      2000       2882 0.567687            -0.012898           14557 -8.860129e-07\n",
      "      2100       2811 0.567643            -0.012854           14628 -8.787108e-07\n",
      "      2200       2710 0.573809            -0.019020           14729 -1.291340e-06\n",
      "      2300       2631 0.573485            -0.018696           14808 -1.262552e-06\n",
      "      2400       2551 0.573208            -0.018420           14888 -1.237207e-06\n",
      "      2500       2488 0.534814             0.019975           14951  1.336002e-06\n",
      "      2600       2435 0.535348             0.019441           15004  1.295737e-06\n",
      "      2700       2368 0.531632             0.023157           15071  1.536495e-06\n",
      "      2800       2311 0.531632             0.023157           15128  1.530706e-06\n",
      "      2900       2259 0.538119             0.016670           15180  1.098162e-06\n",
      "      3000       2201 0.537313             0.017476           15238  1.146860e-06\n",
      "      3100       2142 0.519077             0.035712           15297  2.334577e-06\n",
      "      3200       2087 0.489563             0.065226           15352  4.248687e-06\n",
      "      3300       2042 0.490907             0.063882           15397  4.149008e-06\n",
      "      3400       1993 0.491451             0.063338           15446  4.100625e-06\n",
      "      3500       1947 0.492371             0.062418           15492  4.029031e-06\n",
      "      3600       1910 0.493529             0.061260           15529  3.944884e-06\n",
      "      3700       1870 0.493184             0.061605           15569  3.956923e-06\n",
      "      3800       1838 0.493329             0.061460           15601  3.939467e-06\n",
      "      3900       1814 0.468110             0.086679           15625  5.547452e-06\n",
      "      4000       1784 0.467770             0.087019           15655  5.558512e-06\n",
      "      4100       1745 0.468997             0.085792           15694  5.466540e-06\n",
      "      4200       1710 0.470879             0.083910           15729  5.334704e-06\n",
      "      4300       1683 0.470331             0.084458           15756  5.360350e-06\n",
      "      4400       1653 0.469383             0.085406           15786  5.410228e-06\n",
      "      4500       1622 0.470190             0.084599           15817  5.348599e-06\n"
     ]
    }
   ],
   "source": [
    "# Increasing the minimum number of ratings required increases accuracy but reduces the number of movies\n",
    "# Find the optimal threshold to balance accuracy and number of movies\n",
    "def evaluate_for_threshold(threshold):\n",
    "    ratings_per_movie = all_ratings.groupby('movieId').size()\n",
    "    accepted_movies = ratings_per_movie[ratings_per_movie >= threshold].index\n",
    "    filtered_ratings = all_ratings[all_ratings['movieId'].isin(accepted_movies)]\n",
    "    num_movies = filtered_ratings['movieId'].nunique()\n",
    "    \n",
    "    user_ids = filtered_ratings['userId'].astype('category').cat.codes\n",
    "    title_ids = filtered_ratings['title'].astype('category').cat.codes\n",
    "    sparse_matrix = coo_matrix((filtered_ratings['rating'], (user_ids, title_ids))).tocsr()\n",
    "    similarity_matrix = cosine_similarity(sparse_matrix.T, dense_output=False)\n",
    "    titles = filtered_ratings['title'].astype('category').cat.categories\n",
    "    movie_similarity_df = pd.DataFrame(similarity_matrix.toarray(), index=titles, columns=titles)\n",
    "\n",
    "    # Evaluate predictions\n",
    "    predictions, actuals, titles, mae, rmse, outlier_percent, Nones = evaluate_predictions(train_ratings, test_ratings, movie_similarity_df, global_mean, movie_means)\n",
    "    return num_movies, mae\n",
    "\n",
    "thresholds_0_100 = range(40, 60, 10)\n",
    "thresholds_100_1000 = range(100, 4501, 100)\n",
    "\n",
    "# Combine the two ranges\n",
    "thresholds = list(thresholds_0_100) + list(thresholds_100_1000)\n",
    "results = []\n",
    "\n",
    "for threshold in thresholds:\n",
    "    num_movies, mae = evaluate_for_threshold(threshold)\n",
    "    if mae is not None:\n",
    "        results.append((threshold, num_movies, mae))\n",
    "\n",
    "#Analyze results to select modes\n",
    "results_df = pd.DataFrame(results, columns=['Threshold', 'NumMovies', 'MAE'])\n",
    "results_df['AccuracyImprovement'] = results_df['MAE'].iloc[0] - results_df['MAE']\n",
    "results_df['MovieReduction'] = results_df['NumMovies'].iloc[0] - results_df['NumMovies']\n",
    "results_df['Tradeoff'] = results_df['AccuracyImprovement'] / results_df['MovieReduction']\n",
    "\n",
    "# Select top 5 thresholds based on tradeoff\n",
    "top_thresholds = results_df.sort_values('Tradeoff', ascending=False).head(5)\n",
    "print(\"Optimal Modes:\")\n",
    "print(top_thresholds.to_string(index=False))\n",
    "\n",
    "# Display all results\n",
    "print(\"All Results:\")\n",
    "print(results_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int32')"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies['year'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                     Movie  Expected Rating  Popularity                           genres   year\n",
      "                          Schindler's List         4.430978       73849                        Drama|War 1993.0\n",
      "                               Rear Window         4.321804       24903                   Drama|Thriller 1998.0\n",
      "                        American History X         4.313843       38967                      Crime|Drama 1998.0\n",
      "                              Blade Runner         4.277417       46289           Action|Sci-Fi|Thriller 1982.0\n",
      "                                     Fargo         4.272627       58031      Comedy|Crime|Drama|Thriller 1996.0\n",
      "                                    Snatch         4.250703       32509            Comedy|Crime|Thriller 2000.0\n",
      "                              Forrest Gump         4.245921      100296         Comedy|Drama|Romance|War 1994.0\n",
      "      Wallace & Gromit: The Wrong Trousers         4.234150       17652  Animation|Children|Comedy|Crime 1993.0\n",
      "                                 The Sting         4.232603       18417                           Comedy 1992.0\n",
      "                       Saving Private Ryan         4.229742       58368                 Action|Drama|War 1998.0\n",
      "           Wallace & Gromit: A Close Shave         4.223310       13944        Animation|Children|Comedy 1995.0\n",
      "         Lock, Stock & Two Smoking Barrels         4.201743       24152            Comedy|Crime|Thriller 1998.0\n",
      "                         Full Metal Jacket         4.198631       32501                        Drama|War 1987.0\n",
      "                                Braveheart         4.192282       69482                 Action|Drama|War 1995.0\n",
      "                         L.A. Confidential         4.190615       32837 Crime|Film-Noir|Mystery|Thriller 1997.0\n",
      "                                    Aliens         4.178177       38846   Action|Adventure|Horror|Sci-Fi 1986.0\n",
      "Star Wars: Episode VI - Return of the Jedi         4.177898       67496          Action|Adventure|Sci-Fi 1983.0\n",
      "                                   Amadeus         4.171214       24986                            Drama 1984.0\n",
      "        Indiana Jones and the Last Crusade         4.170565       46401                 Action|Adventure 1989.0\n",
      "                       Requiem for a Dream         4.162363       29235                            Drama 2000.0\n",
      "Rating Interval\n",
      "0-1      0\n",
      "1-2      0\n",
      "2-3     11\n",
      "3-4    225\n",
      "4-5     51\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def recommend_movies(user_ratings, movie_similarity_df, selected_genres, startYear, endYear):\n",
    "    recommendations = []\n",
    "    ratings_count = all_ratings['title'].value_counts()\n",
    "    already_rated = set(ratings['Name'])\n",
    "\n",
    "\n",
    "    # For every movie in the similarity matrix, calculate the expected rating for the user if they haven't seen it\n",
    "    for movie in movie_similarity_df:\n",
    "        if movie not in already_rated:\n",
    "            expected_rating = find_expected_rating(movie, user_ratings, movie_similarity_df, global_mean, movie_means)\n",
    "            if expected_rating is not None:\n",
    "                num_ratings = ratings_count.get(movie, 0)\n",
    "\n",
    "                recommendations.append((movie, expected_rating, num_ratings))\n",
    "\n",
    "    # Sort the recommendations by expected rating and then by popularity\n",
    "    recommendations.sort(key=lambda x: (x[1], x[2]), reverse=True)\n",
    "    recommendations = pd.DataFrame(recommendations, columns=['Movie', 'Expected Rating', 'Popularity'])\n",
    "    recommendations = recommendations.merge(movies[['title', 'genres', 'year']], left_on='Movie', right_on='title', how='left')\n",
    "    recommendations = recommendations.drop(columns=['title'])\n",
    "    recommendations = recommendations[recommendations['year'].between(startYear, endYear)]\n",
    "\n",
    "\n",
    "    recommendations['genres'] = recommendations['genres'].fillna('Any') \n",
    "    if \"Any\" not in selected_genres:\n",
    "        recommendations = recommendations[recommendations['genres'].apply(lambda g: all(genre in g.split('|') for genre in selected_genres))]\n",
    "\n",
    "    return recommendations\n",
    "\n",
    "recommendation_list = recommend_movies(ratings, movie_similarity_df, [\"Any\"], 1981, 2000)\n",
    "print(recommendation_list.head(20).to_string(index=False))\n",
    "\n",
    "bins = [0, 1, 2, 3, 4, 5]\n",
    "labels = ['0-1', '1-2', '2-3', '3-4', '4-5']\n",
    "recommendation_list['Rating Interval'] = pd.cut(recommendation_list['Expected Rating'], bins=bins, labels=labels, right=False)\n",
    "\n",
    "rating_distribution = recommendation_list['Rating Interval'].value_counts().sort_index()\n",
    "print(rating_distribution)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
